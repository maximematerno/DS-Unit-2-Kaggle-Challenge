{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /Users/maximevacher-materno/Downloads/.git/\n",
      "fatal: remote origin already exists.\n",
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 13 (delta 8), reused 8 (delta 8), pack-reused 5\u001b[K\n",
      "Unpacking objects: 100% (13/13), done.\n",
      "From https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge\n",
      " * branch            master     -> FETCH_HEAD\n",
      "   f5efe86..8df744a  master     -> origin/master\n",
      "Updating f5efe86..8df744a\n",
      "Fast-forward\n",
      " module3/assignment_kaggle_challenge_3.ipynb | 176 \u001b[32m++++++\u001b[m\n",
      " module3/lesson_kaggle_challenge_3.ipynb     | 802 \u001b[32m++++++++++++++++++++++++++++\u001b[m\n",
      " 2 files changed, 978 insertions(+)\n",
      " create mode 100644 module3/assignment_kaggle_challenge_3.ipynb\n",
      " create mode 100644 module3/lesson_kaggle_challenge_3.ipynb\n"
     ]
    }
   ],
   "source": [
    "# If you're in Colab...\n",
    "import os, sys\n",
    "\n",
    "    \n",
    "    # Pull files from Github repo\n",
    "\n",
    "!git init .\n",
    "!git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
    "!git pull origin master\n",
    "    \n",
    "    # Change into directory for module\n",
    "os.chdir('module1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 41), (14358, 40))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import warnings \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
    "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
    "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
    "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47520, 41), (11880, 41), (14358, 40))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate = train_test_split(train, train_size=0.80, test_size=0.20, \n",
    "                              stratify=train['status_group'], random_state=42)\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.date_recorded = pd.to_datetime(train.date_recorded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clean(X):\n",
    "    # stop SettingWithCopyWarning\n",
    "    X = X.copy()\n",
    "    \n",
    "    # About 3% of the time, latitude has small values near zero,\n",
    "    # outside Tanzania, so we'll treat these values like zero.\n",
    "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
    "    \n",
    "    # When columns have zeros and shouldn't, they are like null values.\n",
    "    # So we will replace the zeros with nulls, and impute missing values later.\n",
    "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', 'district_code']\n",
    "    for col in cols_with_zeros:\n",
    "        X[col] = X[col].replace(0, np.nan)\n",
    "\n",
    "    # quantity & quantity_group are duplicates\n",
    "    X = X.drop(columns=['quantity_group', 'installer', 'extraction_type_group', \n",
    "                        'extraction_type_class', 'payment_type', 'waterpoint_type_group'])\n",
    "   \n",
    "\n",
    "    #convert date_recorded \n",
    "    X['date_recorded'] = pd.to_datetime(X.date_recorded)\n",
    "\n",
    "    X['year_recorded'] = X['date_recorded'].dt.year\n",
    "\n",
    "    X = X.drop(columns='date_recorded')\n",
    "\n",
    "    # #create a new feature for pump_age\n",
    "    X['pump_age'] = X['year_recorded'] - X.construction_year\n",
    "    \n",
    "    # # replace negative pump ages with nan \n",
    "    # # which also decreased validation accuracy slightly\n",
    "    X['pump_age'] = X['pump_age'].replace([-7, -6, -5, -4, -3, -2, -1], np.nan)\n",
    "\n",
    "    # return the wrangled dataframe\n",
    "    return X\n",
    "\n",
    "train = clean(train)\n",
    "val = clean(validate)\n",
    "test = clean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'region_code', 'district_code', 'population', 'construction_year', 'year_recorded', 'pump_age', 'basin', 'region', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'management', 'management_group', 'payment', 'water_quality', 'quality_group', 'quantity', 'source', 'source_type', 'source_class', 'waterpoint_type']\n"
     ]
    }
   ],
   "source": [
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "# Get a dataframe with all train columns except the target & id\n",
    "train_features = train.drop(columns=[target, 'id'])\n",
    "\n",
    "# Get a list of the numeric features\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Get a series with the cardinality of the nonnumeric features\n",
    "cardinality = train_features.select_dtypes(exclude='number').nunique()\n",
    "\n",
    "# Get a list of all categorical features with cardinality <= 50\n",
    "categorical_features = cardinality[cardinality <= 50].index.tolist()\n",
    "\n",
    "# Combine the lists \n",
    "features = numeric_features + categorical_features\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The status_group column is the target\n",
    "target = 'status_group'\n",
    "\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "X_validate = val.drop(columns=target)\n",
    "y_validate = val[target]\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'basin',\n",
       "                                      'subvillage', 'region', 'lga', 'ward',\n",
       "                                      'public_meeting', 'recorded_by',\n",
       "                                      'scheme_management', 'scheme_name',\n",
       "                                      'permit', 'extraction_type', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'water_quality', 'quality_group',\n",
       "                                      'quantity', 'source', 'source_type',\n",
       "                                      'source_class', 'wate...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
       "                               objective='multi:softprob', random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##XGB Classifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(), \n",
    "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    ")\n",
    "\n",
    "# fit on train, score on val\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.7438552188552189\n"
     ]
    }
   ],
   "source": [
    "print('Validation Accuracy: ', pipeline.score(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:    2.9s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    2.9s remaining:    1.2s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter xgbregressor_learning_rate for estimator Pipeline(memory=None,\n         steps=[('ordinalencoder',\n                 OrdinalEncoder(cols=None, drop_invariant=False,\n                                handle_missing='value', handle_unknown='value',\n                                mapping=None, return_df=True, verbose=0)),\n                ('simpleimputer',\n                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n                               missing_values=nan, strategy='mean',\n                               verbose=0)),\n                ('xgbregressor',\n                 XGBRegressor(base_score=0.5, boos...\n                              colsample_bylevel=1, colsample_bynode=1,\n                              colsample_bytree=1, gamma=0,\n                              importance_type='gain', learning_rate=0.1,\n                              max_delta_step=0, max_depth=3, min_child_weight=1,\n                              missing=nan, n_estimators=100, n_jobs=1,\n                              nthread=None, objective='reg:squarederror',\n                              random_state=42, reg_alpha=0, reg_lambda=1,\n                              scale_pos_weight=1, seed=None, silent=None,\n                              subsample=1, verbosity=1))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 501, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/pipeline.py\", line 164, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\", line 50, in _set_params\n    super().set_params(**params)\n  File \"/Users/maximevacher-materno/anaconda3/lib/python3.7/site-packages/sklearn/base.py\", line 224, in set_params\n    (key, self))\nValueError: Invalid parameter xgbregressor_learning_rate for estimator Pipeline(memory=None,\n         steps=[('ordinalencoder',\n                 OrdinalEncoder(cols=None, drop_invariant=False,\n                                handle_missing='value', handle_unknown='value',\n                                mapping=None, return_df=True, verbose=0)),\n                ('simpleimputer',\n                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n                               missing_values=nan, strategy='mean',\n                               verbose=0)),\n                ('xgbregressor',\n                 XGBRegressor(base_score=0.5, boos...\n                              colsample_bylevel=1, colsample_bynode=1,\n                              colsample_bytree=1, gamma=0,\n                              importance_type='gain', learning_rate=0.1,\n                              max_delta_step=0, max_depth=3, min_child_weight=1,\n                              missing=nan, n_estimators=100, n_jobs=1,\n                              nthread=None, objective='reg:squarederror',\n                              random_state=42, reg_alpha=0, reg_lambda=1,\n                              scale_pos_weight=1, seed=None, silent=None,\n                              subsample=1, verbosity=1))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-da4394c1a9e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    685\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1466\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    664\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 666\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter xgbregressor_learning_rate for estimator Pipeline(memory=None,\n         steps=[('ordinalencoder',\n                 OrdinalEncoder(cols=None, drop_invariant=False,\n                                handle_missing='value', handle_unknown='value',\n                                mapping=None, return_df=True, verbose=0)),\n                ('simpleimputer',\n                 SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n                               missing_values=nan, strategy='mean',\n                               verbose=0)),\n                ('xgbregressor',\n                 XGBRegressor(base_score=0.5, boos...\n                              colsample_bylevel=1, colsample_bynode=1,\n                              colsample_bytree=1, gamma=0,\n                              importance_type='gain', learning_rate=0.1,\n                              max_delta_step=0, max_depth=3, min_child_weight=1,\n                              missing=nan, n_estimators=100, n_jobs=1,\n                              nthread=None, objective='reg:squarederror',\n                              random_state=42, reg_alpha=0, reg_lambda=1,\n                              scale_pos_weight=1, seed=None, silent=None,\n                              subsample=1, verbosity=1))],\n         verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='xgboost')\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ce.OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    'xgbregressor_n_estimator': randint(100, 1000),\n",
    "    'xgbregressor_max_depth': randint(3, 10),\n",
    "    'xgbregressor_learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions= param_distributions,\n",
    "    n_iter=5,\n",
    "    cv=2,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=10,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# print('Best Hyperparameters', search.best_params_)\n",
    "# print('Cross-Validation MAE', -search.best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
